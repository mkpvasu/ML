{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3_Sentiment_Analysis_Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkpvasu/Machine-Learning-Problems/blob/main/HW3_Sentiment_Analysis_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3V3Ec_wTI53"
      },
      "source": [
        "# Predicting sentiment from product reviews\n",
        "\n",
        "### The coding portion will be submitted on EdStem and the concept portion on Gradescope.\n",
        "\n",
        "The goal of this first notebook is to explore logistic regression and feature engineering with sklearn.\n",
        "\n",
        "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
        "\n",
        "* Use Pandas Dataframes to do feature engineering\n",
        "* Train a logistic regression model to predict the sentiment of product reviews.\n",
        "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
        "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
        "* Given a classifier, create a confusion matrix\n",
        "* Compare multiple logistic regression models.\n",
        "\n",
        "Copyright ©2021 Emily Fox, Hunter Schafer, Valentina Staneva.  All rights reserved.  Permission is hereby granted to students registered for University of Washington CSE/STAT 416 for use solely during Autumn Quarter 2021 for purposes of the course.  No other use, copying, distribution, or modification is permitted without prior written consent. Copyrights for third-party components of this work must be honored.  Instructors interested in reusing these course materials should contact the author.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_h1IK-ITI6F"
      },
      "source": [
        "import math\n",
        "import string\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "sns.set()\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDqj6m3gTI6G"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "We will use a dataset consisting of food product reviews on Amazon.com [source](http://jmcauley.ucsd.edu/data/amazon/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8_RiOv4TI6H",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "c2989b76-6137-45fe-ac38-772dbdf4f45d"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "products = pd.read_csv('food_products.csv')\n",
        "\n",
        "products"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7fd3f70-5877-4f1b-8051-b3544a9b118b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e7fd3f70-5877-4f1b-8051-b3544a9b118b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving food_products.csv to food_products.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>summary</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4408</td>\n",
              "      <td>Does increase milk supply</td>\n",
              "      <td>This really helped to increase my milk supply....</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4209</td>\n",
              "      <td>One bad packet ruins the product!</td>\n",
              "      <td>I should have stayed with Idahoan brand. Poor ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8623</td>\n",
              "      <td>CAULIFLOWER PASTA!?</td>\n",
              "      <td>As the pasta cooked, I read the box to see wha...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9439</td>\n",
              "      <td>Tasty and inexpensive</td>\n",
              "      <td>I really like this cereal. The flavor is sligh...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7110</td>\n",
              "      <td>I'm Confused</td>\n",
              "      <td>The label on the bowl says 35 grams is in the ...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>2870</td>\n",
              "      <td>10 times the price</td>\n",
              "      <td>I recently bought Domino 10 lb premium cane su...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>8823</td>\n",
              "      <td>Sweet &amp; Crunchy Peanuts</td>\n",
              "      <td>While these are not the highest quality peanut...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>6343</td>\n",
              "      <td>Annies GF Mac Deluxe</td>\n",
              "      <td>I had been using Annies GF Mac n Cheese, then ...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1248</th>\n",
              "      <td>5801</td>\n",
              "      <td>OK, but Check the Pricing</td>\n",
              "      <td>Dr. Oz recommended this brand of coconut water...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>5115</td>\n",
              "      <td>JUST DOESN'T WORK FOR ME</td>\n",
              "      <td>I TAKE CHANCES WITH THINGS I SHOULDN'T.  END R...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1250 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      product_id  ... rating\n",
              "0           4408  ...    3.0\n",
              "1           4209  ...    1.0\n",
              "2           8623  ...    4.0\n",
              "3           9439  ...    5.0\n",
              "4           7110  ...    2.0\n",
              "...          ...  ...    ...\n",
              "1245        2870  ...    1.0\n",
              "1246        8823  ...    3.0\n",
              "1247        6343  ...    4.0\n",
              "1248        5801  ...    3.0\n",
              "1249        5115  ...    2.0\n",
              "\n",
              "[1250 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orsEw3wXTI6H"
      },
      "source": [
        "## Extract sentiments\n",
        "\n",
        "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLfJ2rzdTI6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979575fa-1f1f-4b69-ee8c-861cff17041a"
      },
      "source": [
        "products = products[products['rating'] != 3]\n",
        "products = products.copy()  # This is to avoid having a view on the old data\n",
        "\n",
        "len(products)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "889"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCMsddLATI6I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "53be48c6-1ad9-44cd-fbda-a8e4c33b8398"
      },
      "source": [
        "plt.title('Number of reviews with a given rating')\n",
        "sns.histplot(products['rating'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f443280c250>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6InKW0hTI6J"
      },
      "source": [
        "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMm_t7TNTI6J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "8c4bdb6d-7ee5-4866-a1f1-d53dedeb473d"
      },
      "source": [
        "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
        "products.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>summary</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4209</td>\n",
              "      <td>One bad packet ruins the product!</td>\n",
              "      <td>I should have stayed with Idahoan brand. Poor ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8623</td>\n",
              "      <td>CAULIFLOWER PASTA!?</td>\n",
              "      <td>As the pasta cooked, I read the box to see wha...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9439</td>\n",
              "      <td>Tasty and inexpensive</td>\n",
              "      <td>I really like this cereal. The flavor is sligh...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7110</td>\n",
              "      <td>I'm Confused</td>\n",
              "      <td>The label on the bowl says 35 grams is in the ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1373</td>\n",
              "      <td>Flat</td>\n",
              "      <td>Doesn't taste like ginger.  Thought it would s...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   product_id                            summary  ... rating  sentiment\n",
              "1        4209  One bad packet ruins the product!  ...    1.0         -1\n",
              "2        8623                CAULIFLOWER PASTA!?  ...    4.0          1\n",
              "3        9439              Tasty and inexpensive  ...    5.0          1\n",
              "4        7110                       I'm Confused  ...    2.0         -1\n",
              "5        1373                               Flat  ...    2.0         -1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeVaGJU1TI6K"
      },
      "source": [
        "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olzgv9IxTI6L"
      },
      "source": [
        "## Build the word count vector for each review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzX_Ll9qTI6L"
      },
      "source": [
        "Let us explore a specific example of a food product. We have information about the product, the review left, and both the rating that was given and the sentiment label we computed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwzSYYwNTI6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bf73d0-cb6d-42fd-881f-498f4253dc6b"
      },
      "source": [
        "products.iloc[21]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "product_id                                                  918\n",
              "summary                                It's PRIME-arily Lobster\n",
              "review        if it's primarily made from lobster, what else...\n",
              "rating                                                        4\n",
              "sentiment                                                     1\n",
              "Name: 34, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VYkZg40TI6M"
      },
      "source": [
        "To work with the text data, we will need to eventually turn it into word counts. In other words, we will be making a feature for every word that could possibly appear in the data, and the value for that feature for one example would be the number of times that word appears in that example. \n",
        "\n",
        "To accomplish this, we will need to do two data transformation:\n",
        "\n",
        "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
        "2. Transform the reviews into word-counts.\n",
        "\n",
        "\n",
        "\n",
        "> **Aside**. In this assignment, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. \n",
        "> \n",
        "> If you are curious in learning how to handle these complexities in practice, you might be interested in  researching more about tokenization and NLP like [this page](https://towardsdatascience.com/tokenization-for-natural-language-processing-a179a891bad4) shows. Note that you do not need to do any of that stuff for this assignment.\n",
        "\n",
        "So first, we remove punctuation with the code in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R65fJRNgTI6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b09e2d-da27-4b72-eebe-2e78371ded06"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    if type(text) is str:\n",
        "        return text.translate(str.maketrans('', '', string.punctuation))\n",
        "    else:\n",
        "        return ''\n",
        "    \n",
        "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
        "products['review_clean']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1       I should have stayed with Idahoan brand Poor B...\n",
              "2       As the pasta cooked I read the box to see what...\n",
              "3       I really like this cereal The flavor is slight...\n",
              "4       The label on the bowl says 35 grams is in the ...\n",
              "5       Doesnt taste like ginger  Thought it would sav...\n",
              "                              ...                        \n",
              "1243    This is the product that rocked my world In a ...\n",
              "1244    I am so glad Amazon has this set up for subscr...\n",
              "1245    I recently bought Domino 10 lb premium cane su...\n",
              "1247    I had been using Annies GF Mac n Cheese then I...\n",
              "1249    I TAKE CHANCES WITH THINGS I SHOULDNT  END RES...\n",
              "Name: review_clean, Length: 889, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCf-Bkd3TI6M"
      },
      "source": [
        "Next, we use scikit-learn's [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to get counts for each word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF6-uqRTTI6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "41035d2b-f9f0-4b6c-cc91-0986a81bc2f8"
      },
      "source": [
        "# Make counts\n",
        "vectorizer = CountVectorizer()\n",
        "count_matrix = vectorizer.fit_transform(products['review_clean'])\n",
        "\n",
        "# Make a new DataFrame with the counts information\n",
        "product_data = pd.DataFrame(count_matrix.toarray(),\n",
        "        index=products.index,\n",
        "        columns=vectorizer.get_feature_names())\n",
        "\n",
        "# Add the old columns to our new DataFrame. \n",
        "# We won't use review_clean and the summary in our model, but we will keep\n",
        "# them to look at later.\n",
        "product_data['sentiment'] = products['sentiment']\n",
        "product_data['review_clean'] = products['review_clean']  \n",
        "product_data['summary'] = products['summary']\n",
        "\n",
        "product_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0000</th>\n",
              "      <th>002</th>\n",
              "      <th>004</th>\n",
              "      <th>004oz</th>\n",
              "      <th>012months</th>\n",
              "      <th>032</th>\n",
              "      <th>051</th>\n",
              "      <th>08</th>\n",
              "      <th>0f</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>100gr</th>\n",
              "      <th>100mg</th>\n",
              "      <th>10112013seller</th>\n",
              "      <th>1012</th>\n",
              "      <th>1024</th>\n",
              "      <th>107</th>\n",
              "      <th>10x</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>1133</th>\n",
              "      <th>114</th>\n",
              "      <th>117i</th>\n",
              "      <th>11g</th>\n",
              "      <th>11ounce</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>1200</th>\n",
              "      <th>1258201cm</th>\n",
              "      <th>125mgmy</th>\n",
              "      <th>128</th>\n",
              "      <th>1292014list</th>\n",
              "      <th>12absolutely</th>\n",
              "      <th>12andcoco</th>\n",
              "      <th>12g</th>\n",
              "      <th>12i</th>\n",
              "      <th>12ounce</th>\n",
              "      <th>12pack</th>\n",
              "      <th>12yr</th>\n",
              "      <th>...</th>\n",
              "      <th>youre</th>\n",
              "      <th>youreal</th>\n",
              "      <th>yours</th>\n",
              "      <th>yourself</th>\n",
              "      <th>youso</th>\n",
              "      <th>youtheyre</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youve</th>\n",
              "      <th>youwhen</th>\n",
              "      <th>youzico</th>\n",
              "      <th>yucateco</th>\n",
              "      <th>yuck</th>\n",
              "      <th>yuckalso</th>\n",
              "      <th>yuckgot</th>\n",
              "      <th>yuckthe</th>\n",
              "      <th>yucky</th>\n",
              "      <th>yuk</th>\n",
              "      <th>yum</th>\n",
              "      <th>yumbbq</th>\n",
              "      <th>yumits</th>\n",
              "      <th>yummier</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yummyflavorfull</th>\n",
              "      <th>yumyum</th>\n",
              "      <th>yup</th>\n",
              "      <th>zabars</th>\n",
              "      <th>zanthan</th>\n",
              "      <th>zero</th>\n",
              "      <th>zhenas</th>\n",
              "      <th>zico</th>\n",
              "      <th>zico1</th>\n",
              "      <th>zico3</th>\n",
              "      <th>zicos</th>\n",
              "      <th>zillion</th>\n",
              "      <th>zinger</th>\n",
              "      <th>zip</th>\n",
              "      <th>ziplock</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_clean</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>I should have stayed with Idahoan brand Poor B...</td>\n",
              "      <td>One bad packet ruins the product!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>As the pasta cooked I read the box to see what...</td>\n",
              "      <td>CAULIFLOWER PASTA!?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I really like this cereal The flavor is slight...</td>\n",
              "      <td>Tasty and inexpensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>The label on the bowl says 35 grams is in the ...</td>\n",
              "      <td>I'm Confused</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>Doesnt taste like ginger  Thought it would sav...</td>\n",
              "      <td>Flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>This is the product that rocked my world In a ...</td>\n",
              "      <td>Fake.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1244</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I am so glad Amazon has this set up for subscr...</td>\n",
              "      <td>Addictive!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>I recently bought Domino 10 lb premium cane su...</td>\n",
              "      <td>10 times the price</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1247</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I had been using Annies GF Mac n Cheese then I...</td>\n",
              "      <td>Annies GF Mac Deluxe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1249</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>I TAKE CHANCES WITH THINGS I SHOULDNT  END RES...</td>\n",
              "      <td>JUST DOESN'T WORK FOR ME</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>889 rows × 7628 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0000  ...                            summary\n",
              "1        0  ...  One bad packet ruins the product!\n",
              "2        0  ...                CAULIFLOWER PASTA!?\n",
              "3        0  ...              Tasty and inexpensive\n",
              "4        0  ...                       I'm Confused\n",
              "5        0  ...                               Flat\n",
              "...    ...  ...                                ...\n",
              "1243     0  ...                              Fake.\n",
              "1244     0  ...                         Addictive!\n",
              "1245     0  ...                 10 times the price\n",
              "1247     0  ...               Annies GF Mac Deluxe\n",
              "1249     0  ...           JUST DOESN'T WORK FOR ME\n",
              "\n",
              "[889 rows x 7628 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jel4tt2WTI6N"
      },
      "source": [
        "We have now created a lot of features to work with! Note that in the table above, we will have one feature for each word taht appeared in the data and the value for that feature is the count of that word in that review. So for example, if review 5 had the word \"dog\" in it 3 times, the value in row 5 and column \"dog\" would be 3.\n",
        "\n",
        "## Split data into training, validation and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN3RlPuMTI6O"
      },
      "source": [
        "Let's perform a train/validation/test split with 80% of the data in the training set, 10% of the data in the validation set, 10% test. Note that we use `random_state=3` so that everyone gets the same result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJWO5vplTI6O"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(product_data, test_size=0.2, random_state=3)\n",
        "validation_data, test_data = train_test_split(test_data, test_size=0.5, random_state=3)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfYV6hQXTI6O"
      },
      "source": [
        "# Baseline: Majority class prediction\n",
        "\n",
        "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points.\n",
        "\n",
        "To \"train\" the majority class classifier, you should simply find the most frequent target in the training data.\n",
        "\n",
        "### **Question 1:** Majority class classifier\n",
        "* Compute the most frequent label and store it in a variable called `majority_label`.\n",
        "* What is the validation accuracy of the majority class classifer. Store your result as a number between 0 and 1 in a variable called `majority_classifier_validation_accuracy`.\n",
        "  \n",
        "  *Hint:* pandas allows you to take the sum of a boolean series - true values are equal to 1, false values are equal 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-FhV9KITI6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a451efc-c360-453a-f362-630e42de1b8f"
      },
      "source": [
        "### edTest(test_q1_majority_classifier) ###\n",
        "\n",
        "# TODO \"Train\" a majority class classifier and calculate its validation accuracy\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "features = vectorizer.get_feature_names()\n",
        "majority_clf = DummyClassifier(strategy='most_frequent').fit(train_data[features], train_data['sentiment'])\n",
        "majority_label = majority_clf.predict(validation_data[features])\n",
        "print(majority_label[0])\n",
        "\n",
        "majority_classifier_validation_accuracy = accuracy_score(validation_data['sentiment'],majority_label)\n",
        "print(majority_classifier_validation_accuracy)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\n",
            "0.5168539325842697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwYCpcnDTI6O"
      },
      "source": [
        "# Train a sentiment classifier with logistic regression\n",
        "\n",
        "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the columns representing word coutnts as features and the column **sentiment** as the target. We will set **no regularization penalty** (and set `random_state=1` to get the same answer as everyone else). \n",
        "\n",
        "You can see scikit-learn's documentation for LogisticRegression [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Note that the parameter for this class to control regularization is named `C` and it represents the inverse of the penalty strenght. In other words $C = \\frac{1}{\\lambda}$. This means to have very little regularization, we make `C` a very large number (corresponding to a very small $\\lambda$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt9j52bOTI6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bebfe86-17dd-4d8f-9318-35c97faee560"
      },
      "source": [
        "features = vectorizer.get_feature_names()\n",
        "\n",
        "# Note: C = 1/Lambda. Setting C to a really high value is the same as setting lambda = 0\n",
        "sentiment_model = LogisticRegression(penalty='none', random_state=1)\n",
        "sentiment_model.fit(train_data[features], train_data['sentiment'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='none',\n",
              "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV0KQoyTTI6P"
      },
      "source": [
        "Let's look at some of the coefficients and the corresponding words. The weights are stored in a `coef_` property: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFl1IWCwTI6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63565ec7-8cfc-4af9-f1ce-90376cafb72a"
      },
      "source": [
        "coefficients = sentiment_model.coef_[0]\n",
        "print('Smallest coefficient', coefficients.min())\n",
        "print('Largest coefficient:', coefficients.max())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smallest coefficient -11.175390439425424\n",
            "Largest coefficient: 19.97931494988929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihGKU_-9TI6Q"
      },
      "source": [
        "### **Question 2:** Most Positive/Negative Word\n",
        "For the sentiment model we trained above, compute the word with the most negative weight and the word with the most positive weight.\n",
        "\n",
        "Store your results in the variables `most_negative_word` and `most_positive_word`.\n",
        "\n",
        "While you only need to write code to compute the most negative and most positive, we also recommend printing out the words with the highest magnitude coefficients to make sure they make sense.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BBZ-WqvTI6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383763ba-86e2-4739-c464-123bd43ea869"
      },
      "source": [
        "### edTest(test_q2_most_pos_neg_words) ###\n",
        "\n",
        "# TODO Find the most positive word and most negative word in the sentiment_model\n",
        "\n",
        "most_negative_word = None\n",
        "most_positive_word = None\n",
        "\n",
        "for i in range(len(coefficients)):\n",
        "  if(coefficients[i] == coefficients.min()):\n",
        "    most_negative_word = features[i]\n",
        "\n",
        "print(most_negative_word)\n",
        "\n",
        "for i in range(len(coefficients)):\n",
        "  if(coefficients[i] == coefficients.max()):\n",
        "    most_positive_word = features[i]\n",
        "\n",
        "print(most_positive_word)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not\n",
            "great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy1azz9ATI6Q"
      },
      "source": [
        "## Making predictions with logistic regression\n",
        "\n",
        "Now that a model is trained, we can make predictions on the **validation data**. In this first section, we will restrict the examples we are looking at to 3 examples in the validation dataset. We refer to this set of 3 examples as the **sample_data**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQCsRiz1TI6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "cef488d4-a43b-456e-db04-a5ef5f1b4532"
      },
      "source": [
        "sample_data = validation_data\n",
        "sample_data[['sentiment', 'review_clean', 'summary']]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_clean</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>1</td>\n",
              "      <td>Great product  keeps well enough that I can or...</td>\n",
              "      <td>The Kids Love it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>-1</td>\n",
              "      <td>This coconut water has a very weird smell and ...</td>\n",
              "      <td>Weird Odor with a Bad After Taste!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154</th>\n",
              "      <td>-1</td>\n",
              "      <td>REally wanted to like this but it has no taste...</td>\n",
              "      <td>Fat free and taste free, sorry to say!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>-1</td>\n",
              "      <td>I know what Ginger tastes like and this is NOT...</td>\n",
              "      <td>NO GOOD!!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>1</td>\n",
              "      <td>Read the reviews here with a grain of salt  A ...</td>\n",
              "      <td>Great product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640</th>\n",
              "      <td>1</td>\n",
              "      <td>We love this cereal both parents child and tod...</td>\n",
              "      <td>Organic Mesa Sunrise is awesome!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>1</td>\n",
              "      <td>If you are still committed to being healthy wh...</td>\n",
              "      <td>The Original</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>-1</td>\n",
              "      <td>ANNIE CHUNG PRODUCTS ARE HORRID  GROSSLY STICK...</td>\n",
              "      <td>NOT WORTH ONE STAR - GIVE IT A ZERO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>-1</td>\n",
              "      <td>I dont have to lose weight However I am fighti...</td>\n",
              "      <td>Maltitol is not what I need</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>1</td>\n",
              "      <td>I cannot drink a lot of strong tea while nursi...</td>\n",
              "      <td>not bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentiment  ...                                 summary\n",
              "169           1  ...                       The Kids Love it!\n",
              "70           -1  ...      Weird Odor with a Bad After Taste!\n",
              "1154         -1  ...  Fat free and taste free, sorry to say!\n",
              "290          -1  ...                             NO GOOD!!!!\n",
              "1021          1  ...                           Great product\n",
              "...         ...  ...                                     ...\n",
              "640           1  ...        Organic Mesa Sunrise is awesome!\n",
              "834           1  ...                            The Original\n",
              "866          -1  ...     NOT WORTH ONE STAR - GIVE IT A ZERO\n",
              "71           -1  ...             Maltitol is not what I need\n",
              "512           1  ...                                 not bad\n",
              "\n",
              "[89 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP6Xli_NTI6Q"
      },
      "source": [
        "### Predicting sentiment\n",
        "Let's start by predicting the sentiment of the 3 examples in the `sample_data`. The `predict_proba` method on the `LogisticRegression` class outputs a probability for each class possible.\n",
        "\n",
        "The output has one row for each example. Each row is an array of 2 numbers, the first is the predictor's prediction for the probability it is a negative sentiment example, and the second is the probability of it being a positive sentiment example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbyxpUKqTI6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd2984d-111b-4108-a9fb-bf4a04863101"
      },
      "source": [
        "print('  Prob Negative, Prob Positive')\n",
        "print(sentiment_model.predict_proba(sample_data[features]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Prob Negative, Prob Positive\n",
            "[[4.88498131e-15 1.00000000e+00]\n",
            " [1.00000000e+00 2.45015249e-29]\n",
            " [9.99996439e-01 3.56051803e-06]\n",
            " [1.00000000e+00 1.26154372e-25]\n",
            " [1.00000000e+00 1.02325122e-23]\n",
            " [1.00000000e+00 7.84843467e-23]\n",
            " [1.00000000e+00 6.80914475e-21]\n",
            " [1.00000000e+00 5.56833915e-22]\n",
            " [1.00000000e+00 1.11693736e-31]\n",
            " [2.33590924e-13 1.00000000e+00]\n",
            " [1.00000000e+00 3.08339283e-22]\n",
            " [1.13051390e-01 8.86948610e-01]\n",
            " [9.93223495e-01 6.77650541e-03]\n",
            " [4.26513802e-09 9.99999996e-01]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [9.99967826e-01 3.21738523e-05]\n",
            " [9.93962129e-01 6.03787141e-03]\n",
            " [1.04360964e-12 1.00000000e+00]\n",
            " [9.99999278e-01 7.21832229e-07]\n",
            " [1.00000000e+00 2.61938118e-36]\n",
            " [4.87165863e-13 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 5.32945598e-35]\n",
            " [2.48863783e-05 9.99975114e-01]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 1.81935693e-13]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.02820863e-09 9.99999999e-01]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [9.99976986e-01 2.30141276e-05]\n",
            " [3.35643336e-03 9.96643567e-01]\n",
            " [1.00000000e+00 3.60266968e-22]\n",
            " [1.00000000e+00 7.66543213e-36]\n",
            " [1.26565425e-14 1.00000000e+00]\n",
            " [1.00000000e+00 9.51851703e-13]\n",
            " [1.00000000e+00 1.16741620e-16]\n",
            " [5.58355424e-02 9.44164458e-01]\n",
            " [1.61470837e-12 1.00000000e+00]\n",
            " [4.07898615e-06 9.99995921e-01]\n",
            " [1.45510659e-04 9.99854489e-01]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [4.16774096e-04 9.99583226e-01]\n",
            " [1.00000000e+00 3.24640953e-14]\n",
            " [1.00000000e+00 4.17590694e-74]\n",
            " [1.00000000e+00 3.80059166e-10]\n",
            " [1.37111016e-06 9.99998629e-01]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [2.22044605e-16 1.00000000e+00]\n",
            " [9.99999874e-01 1.25971477e-07]\n",
            " [1.45125911e-10 1.00000000e+00]\n",
            " [1.00000000e+00 2.92698104e-17]\n",
            " [7.04962494e-07 9.99999295e-01]\n",
            " [1.76785063e-08 9.99999982e-01]\n",
            " [3.63858499e-10 1.00000000e+00]\n",
            " [9.66774871e-01 3.32251290e-02]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [9.99999998e-01 1.80918432e-09]\n",
            " [9.99979740e-01 2.02598957e-05]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.00000000e+00 3.70462712e-12]\n",
            " [2.01003129e-01 7.98996871e-01]\n",
            " [9.99988863e-01 1.11368560e-05]\n",
            " [1.21844135e-02 9.87815587e-01]\n",
            " [2.16671125e-12 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [2.93036706e-11 1.00000000e+00]\n",
            " [1.00000000e+00 5.94229160e-23]\n",
            " [4.57547671e-02 9.54245233e-01]\n",
            " [3.17901261e-12 1.00000000e+00]\n",
            " [3.55271368e-15 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [6.28489691e-05 9.99937151e-01]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [1.26857268e-03 9.98731427e-01]\n",
            " [3.31957805e-02 9.66804220e-01]\n",
            " [1.00000000e+00 1.29320890e-10]\n",
            " [8.50980757e-02 9.14901924e-01]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [9.99999988e-01 1.15021497e-08]\n",
            " [1.00000000e+00 1.33125633e-10]\n",
            " [0.00000000e+00 1.00000000e+00]\n",
            " [3.37396783e-03 9.96626032e-01]\n",
            " [9.99999990e-01 9.57559012e-09]\n",
            " [1.00000000e+00 2.03038731e-22]\n",
            " [1.00000000e+00 2.41726392e-12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFlq2EP5TI6R"
      },
      "source": [
        "We are also able to make predictions using the `predict` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pP7IemCTI6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d77a9f-84e7-464a-9075-30a6b1a872cd"
      },
      "source": [
        "print('Predicted labels')\n",
        "print(sentiment_model.predict(sample_data[features]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels\n",
            "[ 1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1  1 -1 -1  1 -1 -1  1  1 -1  1\n",
            "  1  1  1 -1  1  1  1 -1  1 -1 -1  1 -1 -1  1  1  1  1  1  1 -1 -1 -1  1\n",
            "  1  1 -1  1 -1  1  1  1 -1  1  1 -1 -1  1 -1  1 -1  1  1  1  1 -1  1  1\n",
            "  1  1  1  1  1  1  1 -1  1  1 -1 -1  1  1 -1 -1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2Jy9HpcTI6R"
      },
      "source": [
        "### **Question 3:** Find the most positive (and negative) review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxa7exE4TI6R"
      },
      "source": [
        "We now turn to examining the full **validation_data** dataset <span style=\"color:red\">(not sample_data)</span>, , and use `sklearn` to form predictions on all of the data points for faster performance.\n",
        "\n",
        "Using the `sentiment_model`, find review in the **validation_data** with the **highest probability** of being classified as a **positive review**. Also, find the reivew with the **highest probability** of being classified as a **negative review**. We refer to these as the \"most positive review\" and \"most negative review\" respectively. Store the `review_clean` column value for each of these rows in `most_positive_review` and `most_negative_review` respectively.\n",
        "\n",
        "If there is a tie for the most positive/negative reivew, you should always grab the one that appears *first* in the validation data.\n",
        "\n",
        "*Hint*: Once you know the index of the most positive/negative reviews, use the `.iloc[]` accessor on the DataFrame to get that row and find its `review_clean` value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3DK8sbWTI6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e792c618-ae96-4348-c23e-ffc6541ee217"
      },
      "source": [
        "### edTest(test_q3_most_positive_negative_review) ###\n",
        "\n",
        "# TODO Find the review_clean values for the most positive and most negative review\n",
        "\n",
        "validation_data[['sentiment','review_clean','summary']]\n",
        "valprob = sentiment_model.predict_proba(validation_data[features])\n",
        "posmax = np.argmax(valprob[:,1])\n",
        "most_positive_review = validation_data.iloc[posmax]['review_clean']\n",
        "print(most_positive_review)\n",
        "negmin = np.argmax(valprob[:,0])\n",
        "most_negative_review = validation_data.iloc[negmin]['review_clean']\n",
        "print(most_negative_review)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have been on an organic foods diet for almost a year now and I have become much more sensitive to what I eat and drink Out are the energy drinks loaded with sugars caffeine and artificial ingredients In are the more gentler and natural energy boosters This was  a surprise for me I really liked it and it did give an energy boost without any late energy crashesThe flavor is nice A good palatable taste and feel in the mouth No bad after taste It sits well on the stomach even an empty one It provides and fairly quick ramp up in energy and alertness and lasts for several hours to all day The ramp down in gently and hardly noticeable I like the ingredients and the overall effectI am finding that I need less energy boosting as my diet is becoming cleaner and healthier However I am going to rely on these until the day when I can maintain great energy levels without supports Or at least keeps a few in the fridge for special occasions 5 Stars easy Hope you get as much out of it as I have\n",
            "This coconut water has a very weird smell and a bad after taste like its an old coconut  The other coconut water I have had is the Vita coco and its not bad but its better than this Zico  Zico does not taste fresh at all  If you dont breath you can drink it down  Im going to give the rest of the cartons to my mom I hope she likes it  Ewww\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRkXKVU7TI6S"
      },
      "source": [
        "Do you notice something special about those reviews? They are both pretty long! Here we just count number of words regardless of the length of the review but clearly that can affect the results, and in practice one can use some techniques to normalize the counts to avoid prioritizing long reviews over shorter ones (we will discuss this idea in a future week).\n",
        "\n",
        "### **Question 4:** Compute validation accuracy\n",
        "Compute the validation accuracy for the model we just trained. Report the validationaccuracy as a number between 0 and 1 stored in a variable called `sentiment_model_validation_accuracy`.\n",
        "\n",
        "Below, calculate the accuracy of the predictor using sklearn's [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPDA_YOFTI6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5561435a-0954-41b5-dabd-6a59e53aea74"
      },
      "source": [
        "### edTest(test_q4_sentiment_model_accuracy) ###\n",
        "\n",
        "# TODO Find the validation accuracy of the sentiment model\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "spred = sentiment_model.predict(validation_data[features])\n",
        "\n",
        "sentiment_model_validation_accuracy = accuracy_score(validation_data['sentiment'],spred)\n",
        "print(sentiment_model_validation_accuracy)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6404494382022472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RlNsJOxTI6S"
      },
      "source": [
        "### **Question 5**: Which model?\n",
        "Compare the validation accuracy for this problem with the validation accuracy of the baseline majority class classifier. Which model would you predict will peform better in the future? \n",
        "\n",
        "* If you think the majority class classifier would do better, write `q5 = 'majority_class_classifier'`.\n",
        "* If you think the sentiment model would do better, write `q5 = 'sentiment_model'`.\n",
        "* If you think we can't choose which model will be best yet since we haven't assessed on the test set, write `q5 = 'cannot say'`.\n",
        "\n",
        "Save your variable indiciating your answer in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu8jCG8pTI6S"
      },
      "source": [
        "### edTest(test_q5_which_model) ###\n",
        "\n",
        "# TODO Answer the question posed above.\n",
        "q5 = 'sentiment_model'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62EiPpX-TI6S"
      },
      "source": [
        "# Create a confusion matrix\n",
        "\n",
        "A common tool used when analyzing the peformance of a predictor in a classification problem is to look at the confusion matrix, as well as the overall accuracy.\n",
        "\n",
        "We've created a function that will plot a confusion matrix for you given a set of inputs which are the values that should appear within each cell.\n",
        "Recall that there are four values associated with a confusion matrix: true positive, true negative, false positive, and false negative which we will abberviate as TP, TN, FP, and FN, respecitvely. In other words, for the next problem we have handled the plotting code for you that you can use, but you will need to compute the values for each of the confusion matrix dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YMCUCIQTI6T"
      },
      "source": [
        "def plot_confusion_matrix(tp, fp, fn, tn):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix using the values \n",
        "       tp - True Positive\n",
        "       fp - False Positive\n",
        "       fn - False Negative\n",
        "       tn - True Negative\n",
        "    \"\"\"\n",
        "    data = np.matrix([[tp, fp], [fn, tn]])\n",
        "\n",
        "    sns.heatmap(data,annot=True,xticklabels=['Actual Pos', 'Actual Neg']\n",
        "              ,yticklabels=['Pred. Pos', 'Pred. Neg']) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdrhEeDMTI6T"
      },
      "source": [
        "### **Question 6:** Compute confusion matrix values and plot\n",
        "\n",
        "Write code below that uses the `plot_confusion_matrix` function to show the number of true positive, true negative, false positive, and false negative predictions made by your classifier. You should store the counts for each of these values in the variables:\n",
        "* `tp`\n",
        "* `fp`\n",
        "* `fn`\n",
        "* `tn` \n",
        "\n",
        "You might find it useful to use named parameters here (i.e. you can call `plot_confusion_matrix(tp=X, fp=Y, fn=A, tn=B)` instead of having to get the order of the parameters correct)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjGxE1T_TI6T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "f6f1e718-4531-4147-b460-d522fd6cd628"
      },
      "source": [
        "### edTest(test_q6_confusion_matrix) ###\n",
        "\n",
        "# TODO Compute the four values tp, fp, fn, tn and plot them using plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(validation_data['sentiment'], spred)\n",
        "tp = cm[0][0]\n",
        "fp = cm[0][1]\n",
        "fn = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "\n",
        "plot_confusion_matrix(tp,fp,fn,tn)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r39NSgBqTI6T"
      },
      "source": [
        "## **Question 7 and 8:** Logistic Regression with L2 regularization\n",
        "\n",
        "One of the challenges of creating features from each word is that there are many more features than observations. It is easy to overfit. We will explore the effect of the regularization in this problem.\n",
        "\n",
        "Now that we have written up all the pieces needed for regularized logistic regression, let's explore the benefits of using **L2 regularization** in analyzing sentiment for product reviews. \n",
        "\n",
        "Like in the last assignment, we will train models with various levels of regularization starting with a small amount and then moving to a  large amount. The code here will have some similarities to the code you did in the last assignment, so you will find that to be a useful reference, but this problem will be slightly more complex since we ask you to compute a few values.\n",
        "\n",
        "This code will be counted as two separate questions since you will be computing slightly different values, but we will ask you to compute both of them in the same starter code to reduce code duplication (since the tasks are very similar). \n",
        "\n",
        "We first outline what you should compute for each question and then show some general implementation notes for both problems below. Your task for this problem is to fill out the code inside the loop to compute the values described below.\n",
        "\n",
        "We recommend focusing on the value you need to compute for Q7 and then once you have that working work on the code you need to compute Q8.\n",
        "\n",
        "### **Question 7:** Coefficient Paths\n",
        "For this question we will ask you to compute the coefficent path for each of the features in the model for various values of the regularization constant.\n",
        "\n",
        "For each regularization strength, train a model using that regularization constant and compute table storing the coefficients of each learned predictor. Store the results in a `DataFrame` named `coef_table`.\n",
        "\n",
        "You should end up with an `DataFrame` with column names as `'coefficients \\[L2=1e-02\\]', ... 'coefficients \\[L2=1e+05\\]'`, and a row for each word in `features`. \n",
        "\n",
        "Before the loop, we set up `coef_table` to have the right rows and columns, but your code will need to fill out the rest.\n",
        "\n",
        "### **Question 8:** Train and Validation Accuracies\n",
        "Similar to Q7, we want you to compute the training and validation accuracy for each learned predictor and store that in a `DataFrame` called `accuracies_table`. \n",
        "\n",
        "You should end up with a `DataFrame` with column names `'l2_penalty', 'train_accuracy', 'validation_accuracy'` and a row for each L2 penalty tried. The L2 penaly should be the number (not the column name from Q7) and the accuracy values should be numbers between 0 and 1 for the appropriate accuracy.\n",
        "\n",
        "For this problem, we recommend the approach used in HW2 to build up a list of dictionaries, and then convert that to a `DataFrame` with the values described.\n",
        "\n",
        "### Implementation Details\n",
        "\n",
        "Some important notes about your implementation:\n",
        "* When constructing a `LogisticRegression` object, make sure to use `random_state=1` to get the same results as us. We also want to avoid having an intercept term in this example, so also pass `fit_intercept=False` when constructing the `LogisticRegression` model.\n",
        "* <span style=\"color:red\">When constructing the LogisticRegression(...) model, the parameter `C` is the **inverse** of the L2 penalty (1 / L2_penalty). </span>\n",
        "* Q7: To store the results of your predictor's coefficients, you will need to get the values from the `.coef_` property. Since the code for this is a little complex, we give you this line below (assumes your trained model is stored in a variable called `model`):\n",
        "  ```\n",
        "  coef_table[column_name] = model.coef_[0]\n",
        "  ```\n",
        "\n",
        "  Confusingly this grabs all the coefficients and treats them like a list of numbers rather than the 2D array of rows/columns that scikit-learn originally provides.\n",
        "\n",
        "* It is okay if your code prints `ConvergenceWarnings`. This is something you would want to avoid in practice but is okay in our assignment for simplicity.\n",
        "\n",
        "* We recommend just focusing on Q7 at first and getting the code to set up the coefficients table right. Then once that's working, evaluate the models for Q8.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYQp_28bTI6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719ef2a8-8ee2-48b2-b15c-4b9efc8838a1"
      },
      "source": [
        "### edTest(test_q7_q8_train_models) ###\n",
        "\n",
        "# TODO Fill in the loop below\n",
        "\n",
        "# Set up the regularization penalities to try\n",
        "l2_penalties = [0.01, 1, 4, 10, 1e2, 1e3, 1e5]\n",
        "l2_penalty_names = [f'coefficients [L2={l2_penalty:.0e}]' \n",
        "                    for l2_penalty in l2_penalties]\n",
        "\n",
        "# Q7: Add the coefficients to this coef_table for each model\n",
        "coef_table = pd.DataFrame(columns=['word'] + l2_penalty_names)\n",
        "coef_table['word'] = features\n",
        "\n",
        "# Q8: Set up an empty list to store the accuracies (will convert to DataFrame after loop)\n",
        "accuracy_data = []\n",
        "\n",
        "for l2_penalty, l2_penalty_column_name in zip(l2_penalties, l2_penalty_names):\n",
        "    # TODO(Q7 and Q8): Train the model \n",
        "  logsreg = LogisticRegression(penalty='l2',C=(1/l2_penalty),random_state=0).fit(train_data[features],train_data['sentiment'])\n",
        "    # TODO(Q7): Save the coefficients in coef_table\n",
        "  coef_table[f'coefficients [L2={l2_penalty:.0e}]'] = logsreg.coef_[0]\n",
        "    # TODO(Q8): Calculate and save the train and validation accuracies\n",
        "  train_accuracy = logsreg.score(train_data[features], train_data['sentiment'])\n",
        "  validation_accuracy = logsreg.score(validation_data[features], validation_data['sentiment'])\n",
        "  accuracy_data.append([l2_penalty,train_accuracy,validation_accuracy])\n",
        "acc_table = pd.DataFrame(accuracy_data)\n",
        "accuracies_table = acc_table.rename(columns={0: \"l2_penalty\", 1: \"train_accuracy\", 2: \"validation_accuracy\"})"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07viU73ATI6T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "3b355bb6-1cb6-4ac4-fd75-b8b42562c5f8"
      },
      "source": [
        "# Look at coef_table\n",
        "coef_table"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>coefficients [L2=1e-02]</th>\n",
              "      <th>coefficients [L2=1e+00]</th>\n",
              "      <th>coefficients [L2=4e+00]</th>\n",
              "      <th>coefficients [L2=1e+01]</th>\n",
              "      <th>coefficients [L2=1e+02]</th>\n",
              "      <th>coefficients [L2=1e+03]</th>\n",
              "      <th>coefficients [L2=1e+05]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000</td>\n",
              "      <td>0.076811</td>\n",
              "      <td>0.026139</td>\n",
              "      <td>0.014668</td>\n",
              "      <td>0.009402</td>\n",
              "      <td>0.002636</td>\n",
              "      <td>0.000441</td>\n",
              "      <td>5.004220e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002</td>\n",
              "      <td>-0.000177</td>\n",
              "      <td>-0.000934</td>\n",
              "      <td>-0.001322</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.000419</td>\n",
              "      <td>-0.000027</td>\n",
              "      <td>-4.079967e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004</td>\n",
              "      <td>-0.000177</td>\n",
              "      <td>-0.000934</td>\n",
              "      <td>-0.001322</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.000419</td>\n",
              "      <td>-0.000027</td>\n",
              "      <td>-4.079967e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004oz</td>\n",
              "      <td>-0.000177</td>\n",
              "      <td>-0.000934</td>\n",
              "      <td>-0.001322</td>\n",
              "      <td>-0.001298</td>\n",
              "      <td>-0.000419</td>\n",
              "      <td>-0.000027</td>\n",
              "      <td>-4.079967e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>012months</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>0.001425</td>\n",
              "      <td>0.001527</td>\n",
              "      <td>0.001425</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>5.009339e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7620</th>\n",
              "      <td>zicos</td>\n",
              "      <td>-0.146430</td>\n",
              "      <td>-0.053188</td>\n",
              "      <td>-0.029682</td>\n",
              "      <td>-0.018105</td>\n",
              "      <td>-0.003775</td>\n",
              "      <td>-0.000464</td>\n",
              "      <td>-4.968101e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7621</th>\n",
              "      <td>zillion</td>\n",
              "      <td>-0.082585</td>\n",
              "      <td>-0.053691</td>\n",
              "      <td>-0.038140</td>\n",
              "      <td>-0.025534</td>\n",
              "      <td>-0.004617</td>\n",
              "      <td>-0.000519</td>\n",
              "      <td>-5.021791e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7622</th>\n",
              "      <td>zinger</td>\n",
              "      <td>-0.000275</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>-0.003756</td>\n",
              "      <td>-0.004038</td>\n",
              "      <td>-0.002400</td>\n",
              "      <td>-0.000410</td>\n",
              "      <td>-4.936411e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7623</th>\n",
              "      <td>zip</td>\n",
              "      <td>0.118160</td>\n",
              "      <td>0.053272</td>\n",
              "      <td>0.033318</td>\n",
              "      <td>0.021897</td>\n",
              "      <td>0.005636</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>1.011543e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7624</th>\n",
              "      <td>ziplock</td>\n",
              "      <td>0.131112</td>\n",
              "      <td>0.040580</td>\n",
              "      <td>0.022601</td>\n",
              "      <td>0.013497</td>\n",
              "      <td>0.002569</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>1.928131e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7625 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           word  ...  coefficients [L2=1e+05]\n",
              "0          0000  ...             5.004220e-06\n",
              "1           002  ...            -4.079967e-06\n",
              "2           004  ...            -4.079967e-06\n",
              "3         004oz  ...            -4.079967e-06\n",
              "4     012months  ...             5.009339e-06\n",
              "...         ...  ...                      ...\n",
              "7620      zicos  ...            -4.968101e-06\n",
              "7621    zillion  ...            -5.021791e-06\n",
              "7622     zinger  ...            -4.936411e-06\n",
              "7623        zip  ...             1.011543e-05\n",
              "7624    ziplock  ...             1.928131e-07\n",
              "\n",
              "[7625 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uelVJqoyTI6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1287c61f-1a72-481b-a8f0-52a56788181d"
      },
      "source": [
        "# Look at accuracies_table\n",
        "accuracies_table"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l2_penalty</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>validation_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.674157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.651685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.00</td>\n",
              "      <td>0.998594</td>\n",
              "      <td>0.662921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.00</td>\n",
              "      <td>0.984529</td>\n",
              "      <td>0.640449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100.00</td>\n",
              "      <td>0.886076</td>\n",
              "      <td>0.651685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1000.00</td>\n",
              "      <td>0.706048</td>\n",
              "      <td>0.617978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100000.00</td>\n",
              "      <td>0.594937</td>\n",
              "      <td>0.539326</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   l2_penalty  train_accuracy  validation_accuracy\n",
              "0        0.01        1.000000             0.674157\n",
              "1        1.00        1.000000             0.651685\n",
              "2        4.00        0.998594             0.662921\n",
              "3       10.00        0.984529             0.640449\n",
              "4      100.00        0.886076             0.651685\n",
              "5     1000.00        0.706048             0.617978\n",
              "6   100000.00        0.594937             0.539326"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyRB6L8ITI6U"
      },
      "source": [
        "## **Question 9:** Inspect Coefficients\n",
        "\n",
        "We'll now look at the **coefficients** for the model that were trained above. We will create a table of features and learned coefficients associated with each of the different L2 penalty values.\n",
        "\n",
        "Using **the coefficients trained with L2 penalty 1**, find the 5 most positive words (with largest positive coefficients). Save them to `positive_words`. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to `negative_words`. The result should be the `'word'` column for the these rows. \n",
        "\n",
        "To be specific, the type of the value we are looking for is a `Series` in `pandas` which is the type of a single row or column in a `DataFrame`. When you have a `DataFrame`, it is a structure with rows and columns. When you access a single column as in `df[column_name]`, this returns a `Series` representing that one column. \n",
        "\n",
        "This means your result for each one of these variables should be a `Series` of length 5 for the respective words.\n",
        "\n",
        "\n",
        "*Hint:* You can use the `.nlargest()` and `.nsmallest()` method on an DataFrame to find the top `n` rows sorted according to the value of a specified column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7n8XL8hTI6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "107cfd3b-0fda-4714-d6b8-661fa1e10981"
      },
      "source": [
        "### edTest(test_q9_most_positive_negative) ###\n",
        "\n",
        "# TODO Compute words with the 5 largest coefficients and 5 smallest coefficients\n",
        "positive_words = coef_table.nlargest(5, 'coefficients [L2=1e+00]')\n",
        "negative_words = coef_table.nsmallest(5, 'coefficients [L2=1e+00]')\n",
        "display(positive_words)\n",
        "display(negative_words)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>coefficients [L2=1e-02]</th>\n",
              "      <th>coefficients [L2=1e+00]</th>\n",
              "      <th>coefficients [L2=4e+00]</th>\n",
              "      <th>coefficients [L2=1e+01]</th>\n",
              "      <th>coefficients [L2=1e+02]</th>\n",
              "      <th>coefficients [L2=1e+03]</th>\n",
              "      <th>coefficients [L2=1e+05]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3096</th>\n",
              "      <td>great</td>\n",
              "      <td>3.567489</td>\n",
              "      <td>1.614415</td>\n",
              "      <td>1.088647</td>\n",
              "      <td>0.790860</td>\n",
              "      <td>0.256039</td>\n",
              "      <td>0.042473</td>\n",
              "      <td>0.000471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>best</td>\n",
              "      <td>2.471304</td>\n",
              "      <td>0.967941</td>\n",
              "      <td>0.609657</td>\n",
              "      <td>0.416849</td>\n",
              "      <td>0.110432</td>\n",
              "      <td>0.015732</td>\n",
              "      <td>0.000134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4981</th>\n",
              "      <td>perfect</td>\n",
              "      <td>2.238239</td>\n",
              "      <td>0.891820</td>\n",
              "      <td>0.544215</td>\n",
              "      <td>0.349993</td>\n",
              "      <td>0.072334</td>\n",
              "      <td>0.009277</td>\n",
              "      <td>0.000095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2679</th>\n",
              "      <td>find</td>\n",
              "      <td>1.729509</td>\n",
              "      <td>0.790541</td>\n",
              "      <td>0.546831</td>\n",
              "      <td>0.395605</td>\n",
              "      <td>0.107021</td>\n",
              "      <td>0.014124</td>\n",
              "      <td>0.000123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1925</th>\n",
              "      <td>days</td>\n",
              "      <td>2.204519</td>\n",
              "      <td>0.746993</td>\n",
              "      <td>0.371551</td>\n",
              "      <td>0.189944</td>\n",
              "      <td>0.017645</td>\n",
              "      <td>0.001135</td>\n",
              "      <td>-0.000003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         word  ...  coefficients [L2=1e+05]\n",
              "3096    great  ...                 0.000471\n",
              "863      best  ...                 0.000134\n",
              "4981  perfect  ...                 0.000095\n",
              "2679     find  ...                 0.000123\n",
              "1925     days  ...                -0.000003\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>coefficients [L2=1e-02]</th>\n",
              "      <th>coefficients [L2=1e+00]</th>\n",
              "      <th>coefficients [L2=4e+00]</th>\n",
              "      <th>coefficients [L2=1e+01]</th>\n",
              "      <th>coefficients [L2=1e+02]</th>\n",
              "      <th>coefficients [L2=1e+03]</th>\n",
              "      <th>coefficients [L2=1e+05]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4586</th>\n",
              "      <td>not</td>\n",
              "      <td>-2.331413</td>\n",
              "      <td>-1.054279</td>\n",
              "      <td>-0.761322</td>\n",
              "      <td>-0.602894</td>\n",
              "      <td>-0.270690</td>\n",
              "      <td>-0.058511</td>\n",
              "      <td>-0.000977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>chocolate</td>\n",
              "      <td>-2.391138</td>\n",
              "      <td>-0.776580</td>\n",
              "      <td>-0.440587</td>\n",
              "      <td>-0.289100</td>\n",
              "      <td>-0.087154</td>\n",
              "      <td>-0.018502</td>\n",
              "      <td>-0.000284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>bland</td>\n",
              "      <td>-1.705603</td>\n",
              "      <td>-0.682273</td>\n",
              "      <td>-0.435470</td>\n",
              "      <td>-0.294777</td>\n",
              "      <td>-0.070575</td>\n",
              "      <td>-0.009439</td>\n",
              "      <td>-0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>may</td>\n",
              "      <td>-1.819700</td>\n",
              "      <td>-0.673030</td>\n",
              "      <td>-0.402371</td>\n",
              "      <td>-0.261560</td>\n",
              "      <td>-0.059173</td>\n",
              "      <td>-0.008264</td>\n",
              "      <td>-0.000112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2071</th>\n",
              "      <td>didnt</td>\n",
              "      <td>-2.151109</td>\n",
              "      <td>-0.667828</td>\n",
              "      <td>-0.365014</td>\n",
              "      <td>-0.213864</td>\n",
              "      <td>-0.038331</td>\n",
              "      <td>-0.005752</td>\n",
              "      <td>-0.000088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           word  ...  coefficients [L2=1e+05]\n",
              "4586        not  ...                -0.000977\n",
              "1398  chocolate  ...                -0.000284\n",
              "919       bland  ...                -0.000100\n",
              "4177        may  ...                -0.000112\n",
              "2071      didnt  ...                -0.000088\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7RbCPbzTI6U"
      },
      "source": [
        "Let us observe the effect of increasing L2 penalty on the 10 words just selected. We provide you with a utility function to  plot the coefficient path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym-TbRZwTI6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "8433a858-90b9-4d1a-9daf-6ed2363bb570"
      },
      "source": [
        "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
        "    def get_cmap_value(cmap, i, total_words):\n",
        "        \"\"\"\n",
        "        Computes a nice scaling of from i=0 to i=total_words - 1\n",
        "        for the given cmap\n",
        "        \"\"\"\n",
        "        return cmap(0.8 * ((i + 1) / (total_words * 1.2) + 0.15))\n",
        "\n",
        "\n",
        "    def plot_coeffs_for_words(ax, words, cmap):\n",
        "        \"\"\"\n",
        "        Given an axes to plot on and a list of words and a cmap,\n",
        "        plots the coefficient paths for each word in words\n",
        "        \"\"\"\n",
        "        words_df = table[table['word'].isin(words)]\n",
        "        words_df = words_df.reset_index(drop=True)  # To make indices sequential\n",
        "\n",
        "        for i, row in words_df.iterrows():\n",
        "            color = get_cmap_value(cmap, i, len(words))\n",
        "            ax.plot(xx, row[row.index != 'word'], '-',\n",
        "                    label=row['word'], linewidth=4.0, color=color)\n",
        "\n",
        "    # Make a canvas to draw on\n",
        "    fig, ax = plt.subplots(1, figsize=(10, 6))\n",
        "   \n",
        "    # Set up the xs to plot and draw a line for y=0\n",
        "    xx = l2_penalty_list\n",
        "    ax.plot(xx, [0.] * len(xx), '--', linewidth=1, color='k')\n",
        "\n",
        "    # Plot the positive and negative coefficient paths\n",
        "    cmap_positive = plt.get_cmap('Reds')\n",
        "    cmap_negative = plt.get_cmap('Blues')\n",
        "    plot_coeffs_for_words(ax, positive_words, cmap_positive)\n",
        "    plot_coeffs_for_words(ax, negative_words, cmap_negative)\n",
        "\n",
        "    # Set up axis labels, scale, and legend  \n",
        "    ax.legend(loc='best', ncol=2, prop={'size':16}, columnspacing=0.5 )\n",
        "    ax.set_title('Coefficient path')\n",
        "    ax.set_xlabel('L2 penalty ($\\lambda$)')\n",
        "    ax.set_ylabel('Coefficient value')\n",
        "    ax.set_xscale('log')\n",
        "\n",
        "\n",
        "make_coefficient_plot(coef_table, positive_words, negative_words, l2_penalty_list=l2_penalties)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}